{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Build topic_news and topic_tweets docs\n",
    "**Objective**: aggregate associated news and tweets for each topic into a doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Roadmap\n",
    "1. Build topic_news and topic_tweets docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialization\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "Standard modules\n",
    "'''\n",
    "import os\n",
    "import pickle\n",
    "import sqlite3\n",
    "import time\n",
    "import codecs\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "'''\n",
    "Analysis modules\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "'''\n",
    "Custom modules\n",
    "'''\n",
    "import config\n",
    "import utilities\n",
    "\n",
    "'''\n",
    "Misc\n",
    "'''\n",
    "nb_name = '20171012-daheng-build_topic_news_tweets_docs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Build topic_news and topic_tweets docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.65 s, sys: 3.28 s, total: 5.93 s\n",
      "Wall time: 5.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "Load in topics information pkl\n",
    "'''\n",
    "if 1 == 1:\n",
    "    with open(config.TOPICS_LST_PKL, 'rb') as f:\n",
    "        topics_lst = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "frozen": true,
     "read_only": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Topic_name: Hillary_Clinton_email_controversy; news_num: 228; tweets_num: 860564\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "1 Topic_name: Iran_nuclear_deal; news_num: 406; tweets_num: 2412264\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "2 Topic_name: ISIS_Jihadi_John_identity_reveal; news_num: 101; tweets_num: 620121\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "3 Topic_name: Ukraine_cease_fire; news_num: 84; tweets_num: 603709\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "4 Topic_name: Egypt_free_Al_Jazeera_journalist; news_num: 50; tweets_num: 129120\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "5 Topic_name: Keystone_XL_Pipeline_bill; news_num: 55; tweets_num: 117692\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "6 Topic_name: CIA_Torture_Report; news_num: 41; tweets_num: 167362\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "7 Topic_name: Obama_cybersecurity_plan; news_num: 73; tweets_num: 495576\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "8 Topic_name: DHS_funding_issue; news_num: 45; tweets_num: 104911\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "9 Topic_name: US_Cuba_relationship; news_num: 235; tweets_num: 1213314\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "10 Topic_name: 2015_CPAC; news_num: 68; tweets_num: 289774\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "11 Topic_name: Iraq_free_ISIS_Tikrit; news_num: 94; tweets_num: 567544\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "12 Topic_name: Nigeria_Boko_Haram_terrorists; news_num: 243; tweets_num: 954810\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "13 Topic_name: Ferguson_unrest; news_num: 611; tweets_num: 3406303\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "14 Topic_name: Hong_Kong_protest; news_num: 157; tweets_num: 559130\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "15 Topic_name: Sony_cyberattack; news_num: 275; tweets_num: 1890966\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "16 Topic_name: Bill_Cosby_sexual_assault_allegation; news_num: 168; tweets_num: 636409\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "17 Topic_name: SpaceX_rocket_landing; news_num: 86; tweets_num: 367488\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "18 Topic_name: Brian_Williams_fake_story; news_num: 69; tweets_num: 475319\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "19 Topic_name: HSBC_tax_scandal; news_num: 28; tweets_num: 78053\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "20 Topic_name: David_Carr_death; news_num: 36; tweets_num: 133630\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "21 Topic_name: Patriots_Deflategate; news_num: 44; tweets_num: 268590\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "22 Topic_name: Delhi_Uber_driver_rape; news_num: 36; tweets_num: 381997\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "23 Topic_name: Superbug_spread; news_num: 41; tweets_num: 240141\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "24 Topic_name: Rudy_Giuliani_Obama_critique; news_num: 50; tweets_num: 284510\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "25 Topic_name: Oscar; news_num: 241; tweets_num: 1902567\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "26 Topic_name: Super_Bowl; news_num: 211; tweets_num: 1628441\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "27 Topic_name: Grammy; news_num: 99; tweets_num: 674595\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "28 Topic_name: Golden_Globe; news_num: 79; tweets_num: 826707\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "29 Topic_name: 500_million_Powerball; news_num: 79; tweets_num: 515778\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "30 Topic_name: Thanksgiving; news_num: 150; tweets_num: 1946168\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "31 Topic_name: Black_Friday_and_Cyber_Monday; news_num: 121; tweets_num: 1511633\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "32 Topic_name: Christmas; news_num: 237; tweets_num: 2628846\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "33 Topic_name: New_Year; news_num: 69; tweets_num: 1053027\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "34 Topic_name: Apple_Watch; news_num: 73; tweets_num: 608351\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "35 Topic_name: Yosemite_historic_climb; news_num: 41; tweets_num: 107481\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "36 Topic_name: Jon_Stewart_Daily_Show; news_num: 35; tweets_num: 246313\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "37 Topic_name: success_of_American_Sniper; news_num: 155; tweets_num: 740376\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "38 Topic_name: Ebola_virus_spread; news_num: 173; tweets_num: 888396\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "39 Topic_name: Indonesia_AirAsia_Flight_QZ8501_crash; news_num: 258; tweets_num: 1213037\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "40 Topic_name: Paris_attacks; news_num: 225; tweets_num: 1260586\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "41 Topic_name: Vanuatu_Cyclone_Pam; news_num: 89; tweets_num: 409029\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "42 Topic_name: Malaysia_Airlines_Flight_MH370_crash; news_num: 58; tweets_num: 529421\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "43 Topic_name: Colorado_NAACP_bombing; news_num: 38; tweets_num: 345563\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "44 Topic_name: FSU_shooting; news_num: 39; tweets_num: 171822\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "45 Topic_name: Chapel_Hill_shooting; news_num: 37; tweets_num: 89304\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "46 Topic_name: Bobbi_Kristina_Brown_death; news_num: 49; tweets_num: 129493\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "47 Topic_name: Taliban_Pakistan_school_massacre; news_num: 80; tweets_num: 286289\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "48 Topic_name: American_ISIS_Hostage_Kayla_Mueller; news_num: 38; tweets_num: 74058\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "49 Topic_name: TransAsia_Airways_Flight_GE235_crash; news_num: 56; tweets_num: 220522\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "50 Topic_name: Germanwings_Flight_9525_crash; news_num: 71; tweets_num: 341486\n",
      "\tWriting topic_news doc ...\n",
      "\tWriting topic_tweets doc ...\n",
      "CPU times: user 13min 58s, sys: 34.4 s, total: 14min 32s\n",
      "Wall time: 16min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "For each topic, query db\n",
    " - write news_doc into topic_news doc\n",
    " - write tweet_text into topic_tweets doc\n",
    " \n",
    "All docs are placed inside config.TOPICS_DOCS_DIR\n",
    " - topic_news doc follows name convention: [topic_ind]-[topic_name].news.csv\n",
    " - topic_tweets doc follows name convention: [topic_ind]-[topic_name].tweets.csv\n",
    "\"\"\"\n",
    "\n",
    "if 0 == 1:\n",
    "    '''\n",
    "    Define topic_news and topic_tweets doc format\n",
    "    '''\n",
    "    csv.register_dialect('topics_docs_line', delimiter='\\t', doublequote=True, quoting=csv.QUOTE_ALL)\n",
    "    \n",
    "    for topic_ind, topic in enumerate(topics_lst):\n",
    "        topic_name = topic['name']\n",
    "        news_native_ids_lst = topic['news_native_ids_lst']\n",
    "        tweets_ids_lst = topic['tweets_ids_lst']\n",
    "        \n",
    "        print('{} Topic_name: {}; news_num: {}; tweets_num: {}'.format(topic_ind, topic_name, len(news_native_ids_lst), len(tweets_ids_lst)))\n",
    "        \n",
    "        with sqlite3.connect(config.NEWS_TWEETS_DB_FILE) as conn:\n",
    "            conn.row_factory = sqlite3.Row\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            '''\n",
    "            Write topic_news doc\n",
    "            '''\n",
    "            query_news = '''\n",
    "            select news_title, news_collected_time, news_native_id, news_doc from news\n",
    "            where news_native_id = :news_native_id;'''\n",
    "            \n",
    "            output_file = os.path.join(config.TOPICS_DOCS_DIR, '{}-{}.news.csv'.format(topic_ind, topic_name))\n",
    "            with open(output_file, 'w') as f:\n",
    "                print('\\tWriting topic_news doc ...')\n",
    "                fieldnames = ('news_native_id', 'news_collected_time', 'news_title', 'news_doc')\n",
    "                writer = csv.DictWriter(f, fieldnames=fieldnames, dialect='topics_docs_line')\n",
    "                writer.writeheader()\n",
    "\n",
    "                for news_native_id in news_native_ids_lst:\n",
    "                    cursor.execute(query_news, {'news_native_id': news_native_id})\n",
    "                    for row in cursor.fetchall():\n",
    "                        writer.writerow({'news_native_id': row['news_native_id'],\n",
    "                                         'news_collected_time': row['news_collected_time'],\n",
    "                                         'news_title': row['news_title'],\n",
    "                                         'news_doc': row['news_doc']})\n",
    "                    \n",
    "            \n",
    "            '''\n",
    "            Write topic_tweets doc\n",
    "            \n",
    "            NOTE: tweets_num for each topic is much larger, should use batch query otherwise it would take hours\n",
    "            '''\n",
    "            batch_size = 500\n",
    "                        \n",
    "            output_file = os.path.join(config.TOPICS_DOCS_DIR, '{}-{}.tweets.csv'.format(topic_ind, topic_name))\n",
    "            \n",
    "            with open(output_file, 'w') as f:\n",
    "                print('\\tWriting topic_tweets doc ...')\n",
    "                fieldnames = ('tweet_id', 'tweet_collected_time', 'tweet_text', 'news_native_id')\n",
    "                writer = csv.DictWriter(f, fieldnames=fieldnames, dialect='topics_docs_line')\n",
    "                writer.writeheader()\n",
    "                \n",
    "                '''\n",
    "                Split queries into batches\n",
    "                '''\n",
    "                if len(tweets_ids_lst) % batch_size:\n",
    "                    batch_num = len(tweets_ids_lst) // batch_size + 1\n",
    "                else:\n",
    "                    batch_num = len(tweets_ids_lst) // batch_size\n",
    "                    \n",
    "                for batch_ind in range(0, batch_num):\n",
    "                    start_ind = batch_ind * batch_size\n",
    "                    end_ind = start_ind + batch_size\n",
    "                    \n",
    "                    # build tuple argument containing tweet_native_ids in this batch\n",
    "                    batch_tweets_ids_tpl = tuple(tweets_ids_lst[start_ind: end_ind])\n",
    "                    \n",
    "                    query_tweet = '''\n",
    "                    select tweet_id, tweet_collected_time, tweet_text, news_native_id from tweets\n",
    "                    where tweet_id in ({place_holder});'''.format(place_holder=','.join(['?']*len(batch_tweets_ids_tpl)))\n",
    "\n",
    "                    cursor.execute(query_tweet, batch_tweets_ids_tpl)\n",
    "                    for row in cursor.fetchall():\n",
    "                        writer.writerow({'tweet_id': row['tweet_id'],\n",
    "                                         'tweet_collected_time': row['tweet_collected_time'],\n",
    "                                         'tweet_text': row['tweet_text'].replace('\\n',' '), # keep each tweet in one line\n",
    "                                         'news_native_id': row['news_native_id']})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "3",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
